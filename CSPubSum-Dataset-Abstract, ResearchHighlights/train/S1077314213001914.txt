 We describe SnooperText, an original detector for textual information embedded in photos of building fa√ßades (such as names of stores, products and services) that we developed for the iTowns urban geographic information project. SnooperText locates candidate characters by using toggle-mapping image segmentation and character/non-character classification based on shape descriptors. The candidate characters are then grouped to form either candidate words or candidate text lines. These candidate regions are then validated by a text/non-text classifier using a HOG-based descriptor specifically tuned to single-line text regions. These operations are applied at multiple image scales in order to suppress irrelevant detail in character shapes and to avoid the use of overly large kernels in the segmentation. We show that SnooperText outperforms other published state-of-the-art text detection algorithms on standard image benchmarks. We also describe two metrics to evaluate the end-to-end performance of text extraction systems, and show that the use of SnooperText as a pre-filter significantly improves the performance of a general-purpose OCR algorithm when applied to photos of urban scenes.

@highlight We describe SnooperText, a new text detector specialized for photos of urban scenes.
@highlight Candidate characters are found by toggle segmentation and winnowed by shape descriptors.
@highlight Candidate characters are validated by a HOG-based descriptor.
@highlight SnooperText is better or at least as accurate and robust as other state-of-the-art detectors on standard benchmarks.
@highlight SnooperText was used in iTowns, a prototype system for virtual street-level urban navigation.
