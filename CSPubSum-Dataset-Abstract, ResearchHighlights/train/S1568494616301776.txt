 Teaching-Learning-Based-Optimization (TLBO) is a population-based Evolutionary Algorithm which uses an analogy of the influence of a teacher on the output of learners in a class. TLBO has been reported to obtain very good results for many constrained and unconstrained benchmark functions and engineering problems. The choice for TLBO by many researchers is partially based on the study of TLBO's performance on standard benchmark functions. In this paper, we explore the performance on several of these benchmark functions, which reveals an inherent origin bias within the Teacher Phase of TLBO. This previously unexplored origin bias allows the TLBO algorithm to more easily solve benchmark functions with higher success rates when the objective function has its optimal solution as the origin. The performance on such problems must be studied to understand the performance effects of the origin bias. A geometric interpretation is applied to the Teaching and Learning Phases of TLBO. From this interpretation, the spatial convergence of the population is described, where it is shown that the origin bias is directly tied to spatial convergence of the population. The origin bias is then explored by examining the performance effect due to: the origin location within the objective function, and the rate of convergence. It is concluded that, although the algorithm is successful in many engineering problems, TLBO does indeed have an origin bias affecting the population convergence and success rates of objective functions with origin solutions. This paper aims to inform researchers using TLBO of the performance effects of the origin bias and the importance of discussing its effects when evaluating TLBO.

@highlight A geometric interpretation is applied to explain population convergence.
@highlight A property of TLBO introduces an origin bias in the Teacher Phase.
@highlight A converged population will continue searching in the direction of the origin for better solutions.
@highlight The origin bias is directly tied to convergence.
@highlight A faster rate of convergence yields a higher success rate for problematic functions.
