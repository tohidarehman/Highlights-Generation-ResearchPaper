 Retailers often conduct sequential, single-unit auctions and need to decide the minimum bid in each auction. To reduce inventory costs, it may be optimal to scrap some of the inventory rather than holding it until it is auctioned off. In some auctions, the seller may be uncertain about the market response and hence may want to dynamically learn the demand by observing the number of posted bids. We formulate a Markov decision process (MDP) to study this dynamic auction-design problem under the Vickrey mechanism. We first develop a clairvoyant model where the seller knows the demand distribution. We prove that it is optimal to scrap all inventory above a certain threshold and then auction the remaining units. We derive a first order necessary condition whereby the bidders’ virtual value at an optimal minimum bid equals the seller’s marginal profit. This is a generalization of Riley and Samuelson’s result from the one, single-unit auction case. When the virtual value is strictly increasing, this necessary condition is also sufficient and leads to a structured value iteration algorithm. We then assume that the number of bidders is Poisson distributed but the seller does not know its mean. The seller uses a mixture-of-Gamma prior on this mean and updates this belief over several auctions. This results in a high-dimensional Bayesian MDP whose exact solution is intractable. We therefore propose and compare two approximation methods called certainty equivalent control (CEC) and Q-function approximation. Numerical experiments suggest that Q-function approximation can attain higher revenues than CEC.

@highlight We dynamically optimize minimum bids in a sequence of single-unit auctions.
@highlight A complete characterization of an optimal policy is provided.
@highlight Our model and results are extended to include Bayesian demand learning.
