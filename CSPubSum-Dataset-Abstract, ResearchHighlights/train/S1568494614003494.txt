 Difficult non-linear, mixed integer non-linear and general disjunctive programming (NLP/MINLP/GDP) problems are considered in the present study. We show using random relaxation procedures that sampling over a subset of the integer variables and parallel processing have potential to simplify large scale MINLP/GDP problems and hence to solve them faster and more reliably than conventional approaches on single processors. Gray coding can be utilized to assign problems to the local processors. Some efficient non-linear solvers have been connected to the Genetic Hybrid Algorithm (GHA) through a switch board minlp_machine(), monitoring a vector of caller functions. The switch board is tested on single processor computers and massively parallel supercomputers in a sample of optimization problems. A new line search algorithm based on multi-sectioning, i.e. repeated bi-sectioning of parallel threads is applied to a set of irregular NLP-problems. Simulations indicate that step search based on multi-sectioning and re-centering is robust. Time recording indicates that the step search procedure is fast also in large optimization problems. Parallel processing with Gray coding and random sampling over a subset of the integer variables improves the performance of the sequential quadratic programming algorithm with multi-sectioning in large-scale problems. An early mesh interrupt guarantees load balancing in regular problems. General disjunctive programming (GDP) problems can be simplified through parallel processing. Certain problems are solved in larger scale than reported previously. Function pointer logic and intelligent switching procedures provide a fruitful basis for solving high-order GDP problems, where the computational challenge in direct MINLP-formulations would be insurmountable.

@highlight Difficult NLP-, MINLP- and GDP-problems are solved scalability is achieved by maximizing the intelligence of the processors and minimizing the communication between processors.
@highlight Parallel processing where Gray coding is applied, improves the performance of the algorithm in large-scale problems.
@highlight Large-scale NLP-problems are solved using interior point methodology employing a new exponential barrier function.
@highlight A large-scale disjunctive programming problem is solved on a huge mesh.
