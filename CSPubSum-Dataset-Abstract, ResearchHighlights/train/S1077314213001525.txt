 The majority of methods for the automatic surface reconstruction of an environment from an image sequence have two steps: Structure-from-Motion and dense stereo. From the computational standpoint, it would be interesting to avoid dense stereo and to generate a surface directly from the sparse cloud of 3D points and their visibility information provided by Structure-from-Motion. The previous attempts to solve this problem are currently very limited: the surface is non-manifold or has zero genus, the experiments are done on small scenes or objects using a few dozens of images. Our solution does not have these limitations. Furthermore, we experiment with hand-held or helmet-held catadioptric cameras moving in a city and generate 3D models such that the camera trajectory can be longer than one kilometer.

@highlight The surface is directly estimated from the sparse Structure-from-Motion data.
@highlight Both visibility and manifold constraints are enforced.
@highlight We experiment with hand-held and helmet-held low cost omnidirectional cameras.
@highlight Compact models of complete environments are obtained with low time complexity.
