 3D video has recently seen a massive increase in exposure in our lives. However, differences between the viewing and shooting conditions for a film lead to disparities between the reformed media and the original three-dimensional effect, which cause severe visual fatigue to viewers and result in headaches and dizziness. In this paper, a series of image processing algorithms are introduced to overcome these problems. The image processing pipeline is composed of four steps, eye-pupil detection, stereo correspondence computation, saliency map generation, and 3D warping. Each step is implemented in an S3DS-3D rendering system and its time complexity is measured. From the results, it was found that real-time stereoscopic 3D rendering is impossible using only a software implementation because SIFT and optical flow calculation requires a significant amount of time. Therefore, these two algorithm blocks should be implemented with hardware acceleration. Fortunately, active research is being conducted on these issues and real-time processing is expected to become available soon for applications beyond full-HD TV screens. In addition, it was found that saliency map generation and 3D warping blocks also need to be implemented in hardware for full-HD display although they do not have significant time complexity compared to SIFT and optical flow algorithm blocks.

@highlight We present a real-time stereoscopic 3D rendering pipeline to reduce visual fatigue when watching 3D TV.
@highlight We implement the rendering pipeline in a system based on Linux and Windows.
@highlight Each algorithm of the pipeline is programmed into the system.
@highlight Computational complexity of each algorithm blocks are evaluated with sample 720p and 1080p stereo frames.
@highlight It is found that the real-time stereoscopic 3D rendering is impossible with software implementation only.
