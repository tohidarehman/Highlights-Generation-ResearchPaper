 A large number of biomedical and surveillance applications target at identifying specific events from sensor recordings. These events can be defined as rare and relevant occurrences with a limited duration. When possible, human annotation is available and developed techniques generally adopt the standard recognition approach in which a statistical model is built for the event and non-event classes. However, the goal is not to detect the event in its complete length precisely, but rather to identify the presence of an event, which leads to an inconsistency in the standard framework. This paper proposes an approach in which labels and features are modified so that they are suited for time event detection. The technique consists of an iterative process made of two steps: finding the most discriminant segment inside each event, and synchronizing features. Both steps are performed using a mutual information-based criterion. Experiments are conducted in the context of audio-based automatic cough detection. Results show that the proposed method enhances the process of feature selection, and significantly increases the event detection capabilities compared to the baseline, providing an absolute reduction of the revised event error rate between 4 and 8%. Thanks to these improvements, the audio-only cough detection algorithm outperforms a commercial system using 4 sensors, with an absolute gain of 26% in terms of sensitivity, while preserving the same specificity performance.

@highlight A method is proposed to enhance classifier abilities for supervised event detection.
@highlight The approach relies on the use of mutual information-based measures.
@highlight Applicability is tested in the context of audio-based automatic cough detection.
@highlight Steps of feature selection and classification are significantly improved.
@highlight The resulting technique clearly outperforms the baseline and a commercial system.
