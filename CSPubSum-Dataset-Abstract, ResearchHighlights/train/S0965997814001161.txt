 Recent progress in entertainment and gaming systems has brought more natural and intuitive humanâ€“computer interfaces to our lives. Innovative technologies, such as Xbox Kinect, enable the recognition of body gestures, which are a direct and expressive way of human communication. Although current development toolkits provide support to identify the position of several joints of the human body and to process the movements of the body parts, they actually lack a flexible and robust mechanism to perform high-level gesture recognition. In consequence, developers are still left with the time-consuming and tedious task of recognizing gestures by explicitly defining a set of conditions on the joint positions and movements of the body parts. This paper presents EasyGR (Easy Gesture Recognition), a tool based on machine learning algorithms that help to reduce the effort involved in gesture recognition. We evaluated EasyGR in the development of 7 gestures, involving 10 developers. We compared time consumed, code size, and the achieved quality of the developed gesture recognizers, with and without the support of EasyGR. The results have shown that our approach is practical and reduces the effort involved in implementing gesture recognizers with Kinect.

@highlight We created a tool that facilitates the development of gesture-controlled applications.
@highlight We implemented two recognition techniques: Dynamic Time Warping and Hidden Markov Models.
@highlight We compared the efforts required to develop gesture recognizers, with and without the support of EasyGR.
@highlight We obtained correct-recognition rates of over 99%.
@highlight The results have shown that our approach reduces the effort involved in implementing gesture-controlled applications.
