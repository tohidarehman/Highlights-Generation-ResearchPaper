 Most color cameras are fitted with a single sensor that provides color filter array (CFA) images, in which each pixel is characterized by one of the three color components (either red, green, or blue). To produce a color image, the two missing color components have to be estimated at each pixel of the corresponding CFA image. This process is commonly referred to as demosaicing, and its result as the demosaiced color image. Since demosaicing methods intend to produce “perceptually satisfying” demosaiced color images, they attempt to avoid color artifacts. Because this is often achieved by filtering, demosaicing schemes tend to alter the local texture information that is, however, useful to discriminate texture images. To avoid this issue while exploiting color information for texture classification, it may be relevant to compute texture descriptors directly from CFA images. From chromatic co-occurrence matrices (CCMs) that capture the spatial interaction between color components, we derive new descriptors (CFA CCMs) for CFA texture images. Color textures are then compared by means of the similarity between their CFA CCMs. Experimental results achieved on benchmark color texture databases show the efficiency of this approach for texture classification.

@highlight New descriptors are proposed for color textures, computed from their CFA images.
@highlight These are multi-channel descriptors, like chromatic co-occurrence matrices (CCMs).
@highlight They use specific CFA neighborhoods, allowing to compare textures without demosaicing.
@highlight They outperform CCMs computed from the demosaiced images in classification accuracy.
@highlight Avoiding the demosaicing step, they also save much processing time.
