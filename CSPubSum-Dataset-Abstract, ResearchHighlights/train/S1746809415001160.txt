 Auditory Brain Machine Interfaces were designed for patients with severe neurofunctional disabilities, such as those suffering with late-stage amyotrophic lateral sclerosis (ALS), who have impaired eye movements or are unable to maintain gaze preventing them from using visual strategies for communication. This study explores the three-stimulus auditory oddball paradigm with binary choices (yes/no) associated with Empirical Mode Decomposition to extract features used to train and test a Support Vector Machine classifier. Data from standard EEG channels and from the N200-anterior-contralateral (N2ac) response signal were tested. Ten healthy male subjects, age 20 to 27 years, participated in the experiment. The best performance (average classification accuracy of 87.41% and information transfer ratio of 6.48bit/min) was achieved when features extracted from the N2ac response were added to features extracted from the EEG channels. Also, the results showed that by using target stimuli with larger frequency separation helps the subjects focus better on the desired answer.

@highlight We improved the accuracy of single-trial three-stimuli auditory BMIs.
@highlight We compare features from standard EEG and N200-anterior-contralateral signals.
@highlight The addition of N2ac features significantly improves classification accuracy.
@highlight Target stimuli with larger pitch range facilitate focusing on the desired answer.
@highlight The results are among the best reported to date for single-trial auditory BCIs.
