 This work proposes a novel part-based method for visual object tracking. In our model, keypoints are considered as elementary predictors localizing the target in a collaborative search strategy. While numerous methods have been proposed in the model-free tracking literature, finding the most relevant features to track remains a challenging problem. To distinguish reliable features from outliers and bad predictors, we evaluate feature saliency comprising three factors: the persistence, the spatial consistency, and the predictive power of a local feature. Saliency information is learned during tracking to be exploited in several algorithm components: local prediction, global localization, model update, and scale change estimation. By encoding the object structure via the spatial layout of the most salient features, the proposed method is able to accomplish successful tracking in difficult real life situations such as long-term occlusion, presence of distractors, and background clutter. The proposed method shows its robustness on challenging public video sequences, outperforming significantly recent state-of-the-art trackers. Our Salient Collaborating Features Tracker (SCFT) also demonstrated a high accuracy even if a few local features are available.

@highlight A novel part-based tracking algorithm is proposed.
@highlight Reliable local features are identified through a saliency evaluation mechanism.
@highlight Salient predictors collaborate to achieve a global prediction of the target state.
@highlight We handle real-life difficulties such as occlusion and presence of distractors.
@highlight The drastic decrease of the number of features does not destabilize the tracker.
