 We study the benefits and limits of parallelised Markov chain Monte Carlo (MCMC) sampling in cosmology. MCMC methods are widely used for the estimation of cosmological parameters from a given set of observations and are typically based on the Metropolis–Hastings algorithm. Some of the required calculations can however be computationally intensive, meaning that a single long chain can take several hours or days to calculate. In practice, this can be limiting, since the MCMC process needs to be performed many times to test the impact of possible systematics and to understand the robustness of the measurements being made. To achieve greater speed through parallelisation, MCMC algorithms need to have short autocorrelation times and minimal overheads caused by tuning and burn-in. The resulting scalability is hence influenced by two factors, the MCMC overheads and the parallelisation costs. In order to efficiently distribute the MCMC sampling over thousands of cores on modern cloud computing infrastructure, we developed a Python framework called CosmoHammer  which embeds emcee, an implementation by Foreman-Mackey et al. . We test the performance of CosmoHammer for cosmological parameter estimation from cosmic microwave background data. While Metropolis–Hastings is dominated by overheads, CosmoHammer is able to accelerate the sampling process from a wall time of 30 h on a dual core notebook to 16 min by scaling out to 2048 cores. Such short wall times for complex datasets open possibilities for extensive model testing and control of systematics.

@highlight We analyse MCMC methods for cosmology regarding parallelisability and efficiency.
@highlight We present the Python framework CosmoHammer for parallelised MCMC sampling.
@highlight It enables us to estimate cosmological parameters on high performance clusters.
@highlight To test the efficiency of CosmoHammer we use an elastic cloud computing environment.
