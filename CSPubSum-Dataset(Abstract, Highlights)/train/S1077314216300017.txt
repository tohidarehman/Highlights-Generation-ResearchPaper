 Fully-automated segmentation algorithms offer fast, objective, and reproducible results for large data collections. However, these techniques cannot handle tasks that require contextual knowledge not readily available in the images alone. Thus, the supervision of an expert is necessary. We present a generative model for image segmentation, based on a Bayesian inference. Not only does our approach support an intuitive and convenient user interaction subject to the bottom-up constraints introduced by the image intensities, it also circumvents the main limitations of a human observer—3D visualization and modality fusion. The user “dialogue” with the segmentation algorithm via several mouse clicks in regions of disagreement, is formulated as a continuous probability map, that represents the user’s certainty to whether the current segmentation should be modified. Considering this probability map as the voxel-vise Bernoulli priors on the image labels allows spatial encoding of the user-provided input. The method is exemplified for the segmentation of cerebral hemorrhages (CH) in human brain CT scans; ventricles in degenerative mice brain MRIs, and tumors in multi-modal human brain MRIs and is shown to outperform three interactive, state-of-the-art segmentation methods in terms of accuracy, efficiency and user-workload.

@highlight Interactive 3D medical image segmentation based on a Bayesian inference is suggested.
@highlight User-machine “dialogue” is allowed by a few mouse clicks in regions of disagreement.
@highlight User input is formulated as a probabilistic spatial term in a level-set functional.
@highlight A generic method which accommodates different modalities, e.g. CT and multimodal MRI.
@highlight GUI for clinical uses allows real-time, high performance with minimal user feedback.
