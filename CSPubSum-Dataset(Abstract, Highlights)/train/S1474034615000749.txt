 The current trend towards integrating software agents in safety–critical systems such as drones, autonomous cars and medical devices, which must operate in uncertain environments, gives rise to the need of on-line detection of an unexpected behavior. In this work, on-line monitoring is carried out by comparing environmental state transitions with prior beliefs descriptive of optimal behavior. The agent policy is computed analytically using linearly solvable Markov decision processes. Active inference using prior beliefs allows a monitor proactively rehearsing on-line future agent actions over a rolling horizon so as to generate expectations to discover surprising behaviors. A Bayesian surprise metric is proposed based on twin Gaussian processes to measure the difference between prior and posterior beliefs about state transitions in the agent environment. Using a sliding window of sampled data, beliefs are updated a posteriori by comparing a sequence of state transitions with the ones predicted using the optimal policy. An artificial pancreas for diabetic patients is used as a representative example. uncontrolled or passive dynamics input-gain matrix dictionary of training examples integral operator of the desirability function Gaussian process with mean and covariance k covariance function Kullback–Leibler distance transition probability distribution for the passive dynamics transition probability distribution for the controlled dynamics state transition distribution under optimal control state transition distribution under any implemented control matrix of transition probabilities for the passive dynamics cost function environment internal or hidden state surprise index Twin Kullback-Leibler distance current control action of agent optimal cost-to-go function observable environmental state each state dimension sequence of state transition given system observations sequence of state transition given the specification transition for each state dimension. desirability function monitor’s beliefs a given state transition distribution in the agent environment monitor’s belief distributions over future state transitions distance between belief and state transition distributions kernel width parameter noise variance Kronecker delta function optimal control policy an implemented control policy scaling parameter for Brownian noise Brownian noise blood glucose level hepatic sensitivity insulin sensitivity insulin infusion level glycemic sensor output sensor time-lag parameter sensor calibration parameter

@highlight Active inference drives expectations about future environmental state transitions.
@highlight Probabilistic characterization of a priori beliefs for an optimally behaving agent.
@highlight Twin Gaussian processes are used to detect abnormal behavior.
@highlight A surprise index fast pinpoints anomalous behavior.
