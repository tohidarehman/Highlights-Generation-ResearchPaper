 Evaluation of driving performance is of utmost importance in order to reduce road accident rate. Since driving ability includes visual-spatial and operational attention, among others, head pose estimation of the driver is a crucial indicator of driving performance. This paper proposes a new automatic method for coarse and fine head's yaw angle estimation of the driver. We rely on a set of geometric features computed from just three representative facial keypoints, namely the center of the eyes and the nose tip. With these geometric features, our method combines two manifold embedding methods and a linear regression one. In addition, the method has a confidence mechanism to decide if the classification of a sample is not reliable. The approach has been tested using the CMU-PIE dataset and our own driver dataset. Despite the very few facial keypoints required, the results are comparable to the state-of-the-art techniques. The low computational cost of the method and its robustness makes feasible to integrate it in massive consume devices as a real time application.

@highlight We present a new automatic approach for head yaw angle estimation of the driver.
@highlight We rely on a set of geometric features computed from just three representative facial keypoints.
@highlight The method has a confidence mechanism to decide the reliability of a sample label.
@highlight The results are comparable to the state-of-the-art techniques.
@highlight The method can be easily integrated in massive consume devices.
