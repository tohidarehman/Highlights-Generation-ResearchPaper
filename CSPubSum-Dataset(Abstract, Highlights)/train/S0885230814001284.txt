 Advances on real-time magnetic resonance imaging (RT-MRI) make it suitable to study the dynamic aspects of the upper airway. One of the main challenges concerns how to deal with the large amount of data resulting from these studies, particularly to extract relevant features for analysis such as the vocal tract profiles. A method is proposed, based on a modified active appearance model (AAM) approach, for unsupervised segmentation of the vocal tract from midsagittal RT-MRI sequences. The described approach was designed considering the low inter-frame difference. As a result, when compared to a traditional AAM approach, segmentation is performed faster and model convergence is improved, attaining good results using small training sets. The main goal is to extract the vocal tract profiles automatically, over time, providing identification of different regions of interest, to allow the study of the dynamic features of the vocal tract, for example, during speech production. The proposed method has been evaluated against vocal tract delineations manually performed by four observers, yielding good agreement.

@highlight Vocal tract segmentation considering sequential nature of the RT-MRI data.
@highlight Explicit consideration of vocal tract configurations with an open and closed velum.
@highlight Single, high level segmentation initialisation per speaker, unsupervised operation thereafter.
@highlight Small set of images for training: small manual annotation overhead.
@highlight Evaluation of precision and accuracy over large image set and considering annotated images by four observers.
