 Due to technological improvements, the number and volume of datasets are considerably increasing and bring about the need for additional memory and computational complexity. To work with massive datasets in an efficient way; feature selection, data reduction, rule based and exemplar based methods have been introduced. This study presents a method, which may be called joint generalized exemplar (JGE), for classification of massive datasets. This method aims to enhance the computational performance of NGE by working against nesting and overlapping of hyper-rectangles with reassessing the overlapping parts with the same procedure repeatedly and joining non-overlapped hyper-rectangle sections that falling within the same class. This provides an opportunity to have adaptive decision boundaries, and also employing batch data searching instead of incremental searching. Later, the classification was done in accordance with the distance between each particular query and generalized exemplars. The accuracy and time requirements for classification of synthetic datasets and a benchmark dataset obtained by JGE, NGE and other popular machine learning methods were compared and the achieved results by JGE found acceptable.

@highlight The proposed method depends on human learning. Therefore it is a natural way of classification.
@highlight The main upgrade of JGE, which is derived from NGE, is to have adaptive boundaries.
@highlight The obtained classification accuracies and speeds were acceptable depending upon NGE and other popular ML methods.
@highlight The proposed method can be used with huge datasets and also can be used in real time application depending upon its simplicity and speed.
