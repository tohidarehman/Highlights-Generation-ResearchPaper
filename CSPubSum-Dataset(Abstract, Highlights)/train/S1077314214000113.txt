 Most background modeling techniques use a single leaning rate of adaptation that is inadequate for real scenes because the background model is unable to effectively deal with both slow and sudden illumination changes. This paper presents an algorithm based on a self-adaptive Gaussian mixture to model the background of a scene imaged by a static video camera. Such background modeling is used in conjunction with foreground detection to find objects of interest that do not belong to the background. The model uses a dynamic learning rate with adaptation to global illumination to cope with sudden variations of scene illumination. The algorithm performance is benchmarked using the video sequences created for the Background Models Challenge (BMC) . Experimental results are compared with the performance of other algorithms benchmarked with the BMC dataset, and demonstrate comparable detection rates.

@highlight Dynamic learning-rate adaptation to cope with fast illumination changes.
@highlight Embedded global illumination change factor into GMM and shadow removal formulation.
@highlight MDGKT as pre-processing to reduce noise in the temporal, spatial and spectral domains.
