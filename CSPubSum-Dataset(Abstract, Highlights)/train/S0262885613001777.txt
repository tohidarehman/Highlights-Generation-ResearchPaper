 Identical twins pose a great challenge to face recognition due to high similarities in their appearances. Motivated by the psychological findings that facial motion contains identity signatures and the observation that twins may look alike but behave differently, we develop a talking profile to use the identity signatures in the facial motion to distinguish between identical twins. The talking profile for a subject is defined as a collection of multiple types of usual face motions from the video. Given two talking profiles, we compute the similarities of the same type of face motion in both profiles and then perform the classification based on those similarities. To compute the similarity of each type of face motion, we give higher weights to more abnormal motions which are assumed to carry more identity signature information. Our approach, named Exceptional Motion Reporting Model (EMRM), is unrelated with appearance, and can handle realistic facial motion in human subjects, with no restrictions of speed of motion or video frame rate. We first conduct our experiments on a video database containing 39 pairs of twins. The experimental results demonstrate that identical twins can be distinguished better by the talking profiles over the traditional appearance based approach. Moreover, we collected a non-twin YouTube dataset with 99 subjects. The results on this dataset verified that the talking profile can be the potential biometric. We further conducted an experiment to test the robustness of talking profile to the time. Videos from 10 subjects which span across years or even decades in their lives are collected. The results indicated the robustness of talking profile to the aging process.

@highlight We prove that twins look alike, but they behave differently.
@highlight A talking profile consisting of usual facial motions is proposed as a biometric.
@highlight Our model counts more on abnormal action and gains the superior performance.
@highlight Our experiments show that the talking profile is robust to some aging effect.
