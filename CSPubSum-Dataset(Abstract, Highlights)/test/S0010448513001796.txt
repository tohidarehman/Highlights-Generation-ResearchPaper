 Natural and intuitive interfaces for CAD modeling such as hand gesture controls have received a lot of attention recently. However, in spite of its high intuitiveness and familiarity, their use for actual applications has been found to be less comfortable than a conventional mouse interface because of user physical fatigue over long periods of operation. In this paper, we propose an improved gesture control interface for 3D modeling manipulation tasks that possesses conventional interface level usability with low user fatigue while maintaining a high level of intuitiveness. By analyzing problems associated with previous hand gesture controls in translation, rotation and zooming, we developed a multi-modal control interface GaFinC: Gaze and Finger Control interface. GaFinC can track precise hand positions, recognizes several finger gestures, and utilizes an independent gaze pointing interface for setting the point of interest. To verify the performance of GaFinC, tests of manipulation accuracy and time are conducted and their results are compared with those of a conventional mouse. The comfort and intuitiveness level are also scored by means of user interviews. As a result, although the GaFinC interface posted insufficient performance in accuracy and times compared with a mouse, it shows applicable level performance. Also users found it to be more intuitive than a mouse interface while maintaining a usable level of comfort.

@highlight A multi-modal control method using finger and gaze for 3D manipulation is proposed.
@highlight Independent gaze pointing interface increases the intuitiveness of the zooming task.
@highlight The performance of GaFinC is applicable to actual CAD tools.
@highlight Interviews of user experience report higher intuitiveness than a mouse.
