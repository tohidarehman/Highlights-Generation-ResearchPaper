 The advent of depth cameras has enabled mid-air interactions for shape modeling with bare hands. Typically, these interactions employ a finite set of pre-defined hand gestures to allow users to specify modeling operations in virtual space. However, human interactions in real world shaping processes (such as pottery or sculpting) are complex, iterative, and continuous. In this paper, we show that the expression of user intent in shaping processes can be derived from the geometry of contact between the hand and the manipulated object. Specifically, we describe the design and evaluation of a geometric interaction technique for bare-hand mid-air virtual pottery. We model the shaping of a pot as a gradual and progressive convergence of the potâ€™s profile to the shape of the userâ€™s hand represented as a point-cloud (PCL). Thus, a user does not need to learn, know, or remember any gestures to interact with our system. Our choice of pottery simplifies the geometric representation, allowing us to systematically study how users use their hands and fingers to express the intent of deformation during a shaping process. Our evaluations demonstrate that it is possible to enable users to express their intent for shape deformation without the need for a fixed set of gestures for clutching and deforming a shape.

@highlight We introduce a geometric approach for mid-air virtual pottery design.
@highlight A user can design virtual pots without the need to remember gestures.
@highlight The shape of a pot gradually converges to the point-cloud of the user’s hands.
@highlight Applications are shown with two depth sensors, Leap Motion and SoftKinetic DepthSense.
@highlight User evaluation demonstrates strengths and weaknesses of our approach.
