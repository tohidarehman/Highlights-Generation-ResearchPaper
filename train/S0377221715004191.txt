 This work considers a continuous inventory replenishment system where demand is stochastic and dependent on the state of the environment. A Markov Modulated Poisson Process (MMPP) is utilized to model the demand process where the corresponding embedded Markov Chain represents the state of the environment. The equations to calculate the system inventory measures and the number of orders per unit time are obtained for a continuous, infinite horizon and dynamically changing (s, S) policy. An efficient optimization heuristic is presented and compared to the commonly used approach of approximating the demand-count process over the lead time with a Normal distribution. An investigation of the MMPP demand process is considered where we quantify the impact of variability in the demand-count process which is due to auto-correlation. Our findings indicate that when demand correlation is high, a dynamic control, where the (s, S) policy changes with state of the environment governing the MMPP, is highly superior to the commonly used “static” heuristics. We propose two dynamic policies of varying computational complexity, and cost efficiency, depending on the class of the product (one for class A, and one for classes B and C), to handle such high-correlation situations.

@highlight We consider dynamic (s, S) policies where demand is modeled by a correlated MMPP.
@highlight We present an algorithmic approach to calculate the steady state measures of the inventory system.
@highlight We present heuristics to calculate the optimal policy.
@highlight The impact of correlation on the demand-count process is investigated.
@highlight We compare our policy with existing heuristics utilizing the demand-count Normality assumption.
