 Class imbalance problem occurs when the number of training instances belonging to different classes are clearly different. In this scenario, many traditional classifiers often fail to provide excellent enough classification performance, i.e., the accuracy of the majority class is usually much higher than that of the minority class. In this article, we consider to deal with class imbalance problem by utilizing support vector machine (SVM) classifier with an optimized decision threshold adjustment strategy (SVM-OTHR), which answers a puzzled question: how far the classification hyperplane should be moved towards the majority class? Specifically, the proposed strategy is self-adapting and can find the optimal moving distance of the classification hyperplane according to the real distributions of training samples. Furthermore, we also extend the strategy to develop an ensemble version (EnSVM-OTHR) that can further improve the classification performance. Two proposed algorithms are both compared with many state-of-the-art classifiers on 30 skewed data sets acquired from Keel data set Repository by using two popular class imbalance evaluation metrics: F-measure and G-mean. The statistical results of the experiments indicate their superiority.

@highlight We analyze the reason why SVM can be damaged by class imbalance in theory.
@highlight We propose SVM-OTHR algorithm to find the optimal moving distance of hyperplane.
@highlight We integrate SVM-OTHR into Bagging ensemble framework to promote its robustness.
@highlight The time complexity of SVM-OTHR is merely a little higher than standard SVM.
@highlight Two proposed algorithms often outperform some other bias correction algorithms.
