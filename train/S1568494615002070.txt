 Feature subset selection is a substantial problem in the field of data classification tasks. The purpose of feature subset selection is a mechanism to find efficient subset retrieved from original datasets to increase both efficiency and accuracy rate and reduce the costs of data classification. Working on high-dimensional datasets with a very large number of predictive attributes while the number of instances is presented in a low volume needs to be employed techniques to select an optimal feature subset. In this paper, a hybrid method is proposed for efficient subset selection in high-dimensional datasets. The proposed algorithm runs filter-wrapper algorithms in two phases. The symmetrical uncertainty (SU) criterion is exploited to weight features in filter phase for discriminating the classes. In wrapper phase, both FICA (fuzzy imperialist competitive algorithm) and IWSSr (Incremental Wrapper Subset Selection with replacement) in weighted feature space are executed to find relevant attributes. The new scheme is successfully applied on 10 standard high-dimensional datasets, especially within the field of biosciences and medicine, where the number of features compared to the number of samples is large, inducing a severe curse of dimensionality problem. The comparison between the results of our method and other algorithms confirms that our method has the most accuracy rate and it is also able to achieve to the efficient compact subset.

@highlight A hybrid method is proposed for efficient subset selection in high-dimensional datasets. The symmetrical uncertainty (SU) criterion is exploited to weight features in filter phase.
@highlight In wrapper phase, both fuzzy imperialist competitive algorithm (FICA) and Incremental Wrapper Subset Selection with replacement (IWSSr) in weighted feature space are executed to search and find relevant attributes.
@highlight The proposed method has been assessed by applying on 10 standard high-dimensional datasets. We compared our proposed algorithm with other five hybrid algorithms (LFS, IWSS, IWSSr, BARS, and Grasp) and two filter methods (FCBF and PCA). The comparison between the results of our method and others confirms that our method has the best accuracy.
@highlight The average number of attributes selected by proposed algorithm is considerably less than the other methods.
@highlight The diagrams show low convergence time and low number of iterations with regard to other methods.
