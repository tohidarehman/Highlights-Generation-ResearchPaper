 One of humansâ€™ auditory abilities is differentiation between sounds with slightly different frequencies. Recently, the auditory image model (AIM) was developed to numerically explain this auditory phenomenon. Acoustic analyses of snore sounds have been performed recently by using non-contact microphones. Snore/non-snore classification techniques have been required at the front-end of snore analyses. The performances of sound classification methods can be evaluated based on human hearing, which is considered to be the gold standard. In this paper, we propose a novel method of automatically extracting snore sounds from sleep sounds by using an AIM-based snore/non-snore classification system. We report that the proposed automatic classification method could achieve a sensitivity of 97.2% and specificity of 96.3% when analyzing snore and non-snore sounds from 40 subjects. It is anticipated that our findings will contribute to the development of an automated snore analysis system to be used in sleep studies.

@highlight We proposed a novel approach to automatically classify snore and non-snore in the sleep sound recordings.
@highlight The auditory image model was employed to extract the sound features.
@highlight The simulation results demonstrate that the proposed method provided high classification accuracy.
