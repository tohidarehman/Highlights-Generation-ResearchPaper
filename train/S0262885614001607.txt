 Visual tracking is an important task in various computer vision applications including visual surveillance, human computer interaction, event detection, video indexing and retrieval. Recent state of the art sparse representation (SR) based trackers show better robustness than many of the other existing trackers. One of the issues with these SR trackers is low execution speed. The particle filter framework is one of the major aspects responsible for slow execution, and is common to most of the existing SR trackers. In this paper, An earlier brief version of the paper has appeared in ICIP'13 (R. Venkatesh Babu and P. Priti, “Interest points based object tracking via sparse representation”, in proceedings of International Conference on Image Processing (ICIP), Melbourne, Australia, 2013). we propose a robust interest point based tracker in l 1 minimization framework that runs at real-time with performance comparable to the state of the art trackers. In the proposed tracker, the target dictionary is obtained from the patches around target interest points. Next, the interest points from the candidate window of the current frame are obtained. The correspondence between target and candidate points is obtained via solving the proposed l 1 minimization problem. In order to prune the noisy matches, a robust matching criterion is proposed, where only the reliable candidate points that mutually match with target and candidate dictionary elements are considered for tracking. The object is localized by measuring the displacement of these interest points. The reliable candidate patches are used for updating the target dictionary. The performance and accuracy of the proposed tracker is benchmarked with several complex video sequences. The tracker is found to be considerably fast as compared to the reported state of the art trackers. The proposed tracker is further evaluated for various local patch sizes, number of interest points and regularization parameters. The performance of the tracker for various challenges including illumination change, occlusion, and background clutter has been quantified with a benchmark dataset containing 50 videos.

@highlight The proposed tracker combines the flexibility of interest points and robustness of sparse representation.
@highlight Proposed a robust matching criteria for reliable tracking via L1 minimization
@highlight The proposed tracker is computationally efficient and provides real-time performance.
@highlight The tracker is benchmarked with many publicly available complex video sequences.
@highlight Performance is compared with many recent state of the art trackers using 50 benchmark video dataset.
