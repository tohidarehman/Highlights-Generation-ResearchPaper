 Recently, a novel probabilistic model-building evolutionary algorithm (so called estimation of distribution algorithm, or EDA), named probabilistic model building genetic network programming (PMBGNP), has been proposed. PMBGNP uses graph structures for its individual representation, which shows higher expression ability than the classical EDAs. Hence, it extends EDAs to solve a range of problems, such as data mining and agent control. This paper is dedicated to propose a continuous version of PMBGNP for continuous optimization in agent control problems. Different from the other continuous EDAs, the proposed algorithm evolves the continuous variables by reinforcement learning (RL). We compare the performance with several state-of-the-art algorithms on a real mobile robot control problem. The results show that the proposed algorithm outperforms the others with statistically significant differences.

@highlight This paper proposes a novel continuous estimation of distribution algorithm (EDA).
@highlight A recent EDA named PMBGNP is extended from discrete domain to continuous domain.
@highlight Reinforcement Learning (RL) is applied to construct the probabilistic model.
@highlight Experiments on real mobile robot control show the superiority of the proposed algorithm.
@highlight It bridges the gap between EDA and RL.
