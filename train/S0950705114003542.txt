 Extreme Learning Machine (ELM) has received increasing attention for its simple principle, low computational cost and excellent performance. However, a large number of labeled instances are often required, and the number of hidden nodes should be manually tuned, for better learning and generalization of ELM. In this paper, we propose a Sparse Semi-Supervised Extreme Learning Machine (S3ELM) via joint sparse regularization for classification, which can automatically prune the model structure via joint sparse regularization technology, to achieve more accurate, efficient and robust classification, when only a small number of labeled training samples are available. Different with most of greedy-algorithms based model selection approaches, by using -norm, S3ELM casts a joint sparse constraints on the training model of ELM and formulate a convex programming. Moreover, with a Laplacian, S3ELM can make full use of the information from both the labeled and unlabeled samples. Some experiments are taken on several benchmark datasets, and the results show that S3ELM is computationally attractive and outperforms its counterparts.

@highlight A joint sparse regularizer is employed to prune ELM.
@highlight A semi-supervised strategy is used to exploit the information of unlabeled samples.
@highlight S3ELM is proposed to solve the pruning ELM model.
@highlight The proof of the convergence of S3ELM is shown.
