 This paper proposes a new method to extract a gait feature from a raw gait video directly. The Spaceâ€“Time Interest Points (STIPs) are detected where there are significant movements of human body along both spatial and temporal directions in local spatio-temporal volumes of a raw gait video. Then, a histogram of STIP descriptors (HSD) is constructed as a gait feature. In the classification stage, the support vector machine (SVM) is applied to recognize gaits based on HSDs. In this study, the standard multi-class (i.e. multiple subjects) classification can often be computationally infeasible at test phase, when gait recognition is performed by using every possible classifiers (i.e. SVM models) trained for all individual subjects. In this paper, the attribute-based classification is applied to reduce the number of SVM models needed for recognizing each probe gait. This process will significantly reduce the test-time computational complexity and also retain or even improve the recognition accuracy. When compared with other existing methods in the literature, the proposed method is shown to have the promising performance for the case of normal walking, and the outstanding performance for the cases of walking with variations such as walking with carrying a bag and walking with varying a type of clothes.

@highlight A new gait feature is extracted from a raw gait video directly.
@highlight The proposed gait feature extraction is performed in the spatio-temporal domain.
@highlight The attribute-based learning is used to enhance the SVM-based gait classification.
@highlight The proposed method has outstanding performances under changes of clothing types.
@highlight The proposed method has outstanding performances under changes of carry conditions.
