 Nowadays, many real applications comprise data-sets where the distribution of the classes is significantly different. These data-sets are commonly known as imbalanced data-sets. Traditional classifiers are not able to deal with these kinds of data-sets because they tend to classify only majority classes, obtaining poor results for minority classes. The approaches that have been proposed to address this problem can be categorized into three types: resampling methods, algorithmic adaptations and cost sensitive techniques. Radial Basis Function Networks (RBFNs), artificial neural networks composed of local models or RBFs, have demonstrated their efficiency in different machine learning areas. Centers, widths and output weights for the RBFs must be determined when designing RBFNs. Taking into account the locally tuned response of RBFs, the objective of this paper is to study the influence of global and local paradigms on the weights training phase, within the RBFNs design methodology, for imbalanced data-sets. Least Mean Square and the Singular Value Decomposition have been chosen as representatives of local and global weights training paradigms respectively. These learning algorithms are inserted into classical RBFN design methods that are run on imbalanced data-sets and also on these data-sets preprocessed with re-balance techniques. After applying statistical tests to the results obtained, some guidelines about the RBFN design methodology for imbalanced data-sets are provided.

@highlight We present a study about the performance of two classical weight training methods of Radial Basis Function Networks (RBFN), Least Mean Square (LMS) and Singular Value Decomposition (SVD), applied to classification problems, when the data-sets are imbalanced.
@highlight These methods are tested with representative RBFN design paradigms: Clustering, Incremental, Genetic and CO2RBFN (a cooperativeâ€“competitive method proposed by the authors).
@highlight The results obtained, statistically validated, show that SVD outperforms LMS, when the imbalance ratio of data-sets is low but when the imbalance ratio of these data sets grows, LMS outperforms SVD.
