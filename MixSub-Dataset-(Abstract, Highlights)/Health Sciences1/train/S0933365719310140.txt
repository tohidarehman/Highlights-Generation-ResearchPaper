 Explainable AI aims at building intelligent systems that are able to provide a clear and human understandable justification of their decisions . This holds for both rule based and data driven methods . In management of chronic diseases the users of such systems are patients that follow strict dietary rules to manage such diseases . After receiving the input of the intake food the system performs reasoning to understand whether the users follow an unhealthy behavior . Successively the system has to communicate the results in a clear and effective way that is the output message has to persuade users to follow the right dietary rules . In this paper we address the main challenges to build such systems the Natural Language Generation of messages that explain the reasoner inconsistency and the effectiveness of such messages at persuading the users . Results prove that the persuasive explanations are able to reduce the unhealthy users behaviors .

@highlight We present an Explainable AI system based on logical reasoning that supports the monitoring of users behaviors and persuades them to follow healthy lifestyles.
@highlight The ontology is exploited by a SPARQL based reasoner for detecting undesired situations within users behaviors i.e. verifying if user s dietary and activities actions are consistent with the monitoring rules defined by domain experts.
@highlight The core part of the Natural Language Generation component relies on templates a grammar that encode the several parts feedback arguments and suggestion of a persuasion message.
@highlight Results compare the persuasive explanations with simple notifications of inconsistencies and show that the former are able to support users in improving their adherence to dietary rules.
