 Visual relational reasoning is a central component in recent cross modal analysis tasks which aims at reasoning about the visual relationships between objects and their properties . These relationships provide rich semantics and help to enhance the visual representation for improving cross modal learning . Previous works have succeeded in modeling latent visual relationships or rigid categorized visual relationships . However these kinds of methods leave out the problem of ambiguity inherent in the visual relationships because of the diverse relational semantics of different visual appearances . In this work we explore to model the visual relationships by context aware representations based on human prior knowledge . Based on such representations we novelly propose a plug and play visual relational reasoning module to enhance image encoding . Specifically we design an Anisotropic Graph Convolution to utilize the information of relation embeddings and relation directionality between objects for generating relation aware image representations . We demonstrate the effectiveness of the relational reasoning module by applying it to both Visual Question Answering and Cross Modal Information Retrieval tasks . Extensive experiments are conducted on

@highlight Human prior knowledge facilitates visual relational reasoning.
@highlight Anisotropic Graph Convolution can generate relation aware image representation.
@highlight Relational Reasoning module is plug and play.
