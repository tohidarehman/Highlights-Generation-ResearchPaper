 Preharvest crop yield prediction is critical for grain policy making and food security . Early estimation of yield at field or plot scale also contributes to high throughput plant phenotyping and precision agriculture . New developments in Unmanned Aerial Vehicle platforms and sensor technology facilitate cost effective data collection through simultaneous multi sensor multimodal data collection at very high spatial and spectral resolutions . The objective of this study is to evaluate the power of UAV based multimodal data fusion using RGB multispectral and thermal sensors to estimate soybean grain yield within the framework of Deep Neural Network . RGB multispectral and thermal images were collected using a low cost multi sensory UAV from a test site in Columbia Missouri USA . Multimodal information such as canopy spectral structure thermal and texture features was extracted and combined to predict crop grain yield using Partial Least Squares Regression Random Forest Regression Support Vector Regression input level feature fusion based DNN and intermediate level feature fusion based DNN . The results can be summarized in three messages multimodal data fusion improves the yield prediction accuracy and is more adaptable to spatial variations DNN based models improve yield prediction model accuracy the highest accuracy was obtained by DNN F2 with an R

@highlight A low cost multi sensor UAV for crop monitoring phenotyping was developed.
@highlight Canopy structure temperature and texture are important features for yield model.
@highlight Multimodal data fusion showed effectiveness in yield prediction.
@highlight DNN provided promising results in yield prediction across genotypes and over space.
