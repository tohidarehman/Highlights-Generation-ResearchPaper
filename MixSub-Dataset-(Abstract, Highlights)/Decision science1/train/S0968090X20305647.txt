 Variable speed limit control is a flexible way to improve traffic conditions increase safety and reduce emissions . There is an emerging trend of using reinforcement learning methods for VSL control . Currently deep learning is enabling reinforcement learning to develop autonomous control agents for problems that were previously intractable . In this paper a more effective deep reinforcement learning model is developed for differential variable speed limit control in which dynamic and distinct speed limits among lanes can be imposed . The proposed DRL model uses a novel actor critic architecture to learn a large number of discrete speed limits in a continuous action space . Different reward signals such as total travel time bottleneck speed emergency braking and vehicular emissions are used to train the DVSL controller and a comparison between these reward signals is conducted . The proposed DRL based DVSL controllers are tested on a freeway with a simulated recurrent bottleneck . The simulation results show that the DRL based DVSL control strategy is able to improve the safety efficiency and environment friendliness of the freeway . In order to verify whether the controller generalizes to real world implementation we also evaluate the generalization of the controllers on environments with different driving behavior attributes . and the robustness of the DRL agent is observed from the results .

@highlight A deep reinforcement learning method for differential variable speed limit control.
@highlight The reward engineering issue.
@highlight Improve freeway throughput reduce emission and enhance safety.
@highlight The generalization capability of deep reinforcement learning.
